{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8114d6-5ba7-40a3-b611-de58600e6e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the dataset:\n",
      "  label                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   label    5572 non-null   object\n",
      " 1   message  5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "\n",
      "Label Distribution:\n",
      "label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "# It's a tab-separated file, so we use sep='\\t'\n",
    "# We'll also name the columns for clarity\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', names=['label', 'message'])\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Get some basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# See the distribution of labels\n",
    "print(\"\\nLabel Distribution:\")\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab0d167-a966-42f6-9d99-97e1e3425a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows with encoded labels:\n",
      "  label                                            message  label_encoded\n",
      "0   ham  Go until jurong point, crazy.. Available only ...              0\n",
      "1   ham                      Ok lar... Joking wif u oni...              0\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...              1\n",
      "3   ham  U dun say so early hor... U c already then say...              0\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...              0\n",
      "\n",
      "Training data size: 4457\n",
      "Testing data size: 1115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Encode the labels\n",
    "# Convert 'ham' and 'spam' into 0 and 1\n",
    "encoder = LabelEncoder()\n",
    "df['label_encoded'] = encoder.fit_transform(df['label'])\n",
    "\n",
    "# Now, 'ham' is 0 and 'spam' is 1\n",
    "print(\"\\nFirst 5 rows with encoded labels:\")\n",
    "print(df.head())\n",
    "\n",
    "# 2. Define our features (X) and target (y)\n",
    "X = df['message']\n",
    "y = df['label_encoded']\n",
    "\n",
    "# 3. Split the data into training and testing sets\n",
    "# We train the model on the training set and evaluate it on the unseen testing set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"\\nTraining data size: {len(X_train)}\")\n",
    "print(f\"Testing data size: {len(X_test)}\")\n",
    "\n",
    "# 4. Create and fit the TF-IDF Vectorizer\n",
    "# This learns the vocabulary from our training data and converts text to vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Learn the vocabulary and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Only transform the test data (using the vocabulary learned from training)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69caf0cb-b346-4969-b889-630c526cd141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- RUN THIS CELL FIRST! ---\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model on the TF-IDF transformed training data\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\nModel trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2a143b-eafe-48ac-ba99-455fe16158f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy: 97.13%\n",
      "\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "Ham (Legitimate)       0.97      1.00      0.98       966\n",
      " Spam (Phishing)       1.00      0.79      0.88       149\n",
      "\n",
      "        accuracy                           0.97      1115\n",
      "       macro avg       0.98      0.89      0.93      1115\n",
      "    weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[966   0]\n",
      " [ 32 117]]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Print a detailed classification report\n",
    "# Precision: Of all messages predicted as spam, how many were actually spam?\n",
    "# Recall: Of all the actual spam messages, how many did we correctly identify?\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ham (Legitimate)', 'Spam (Phishing)']))\n",
    "\n",
    "# Display the confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5df440-8072-449c-a12f-e37de132b475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing message: 'Hey, are we still on for the meeting tomorrow at 2pm?'\n",
      "Prediction: HAM (Legitimate) | Spam Probability: 0.41%\n",
      "\n",
      "Testing message: 'Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/scamlink to claim now.'\n",
      "Prediction: SPAM (Phishing) | Spam Probability: 69.39%\n",
      "\n",
      "Testing message: 'URGENT: Your account has been compromised. Please verify your identity by clicking here immediately.'\n",
      "Prediction: SPAM (Phishing) | Spam Probability: 63.63%\n"
     ]
    }
   ],
   "source": [
    "def predict_message(message):\n",
    "    \"\"\"\n",
    "    Takes a string message and predicts if it's ham or spam.\n",
    "    \"\"\"\n",
    "    # Transform the new message using the same vectorizer\n",
    "    message_tfidf = tfidf_vectorizer.transform([message])\n",
    "    \n",
    "    # Make a prediction\n",
    "    prediction = model.predict(message_tfidf)\n",
    "    \n",
    "    # Get the probability of it being spam\n",
    "    prediction_prob = model.predict_proba(message_tfidf)[0][1]\n",
    "    \n",
    "    if prediction[0] == 0:\n",
    "        return f\"Prediction: HAM (Legitimate) | Spam Probability: {prediction_prob:.2%}\"\n",
    "    else:\n",
    "        return f\"Prediction: SPAM (Phishing) | Spam Probability: {prediction_prob:.2%}\"\n",
    "\n",
    "# --- Test with some examples ---\n",
    "\n",
    "# Example 1: A likely legitimate message\n",
    "test_ham = \"Hey, are we still on for the meeting tomorrow at 2pm?\"\n",
    "print(f\"\\nTesting message: '{test_ham}'\")\n",
    "print(predict_message(test_ham))\n",
    "\n",
    "# Example 2: A classic spam/phishing message\n",
    "test_spam = \"Congratulations! You've won a $1000 Walmart gift card. Go to http://bit.ly/scamlink to claim now.\"\n",
    "print(f\"\\nTesting message: '{test_spam}'\")\n",
    "print(predict_message(test_spam))\n",
    "\n",
    "# Example 3: Another spam message\n",
    "test_spam_2 = \"URGENT: Your account has been compromised. Please verify your identity by clicking here immediately.\"\n",
    "print(f\"\\nTesting message: '{test_spam_2}'\")\n",
    "print(predict_message(test_spam_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654cfc96-7a4a-4ef7-9505-76ad4b2a8dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
